{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker/DeepAR Model Hyperparameter Tuning Demo\n",
    "This notebook runs a hyperparameter tuning job to find the best parameters to train a DeepAR model. It then trains a model using those parameters, deploys the model and test it.\n",
    "\n",
    "__You don't have to run this notebook__ and can directly use the the `model-creation-and-testing.ipynb` notebook, which uses results of a hyperparameter tuning job ran during our initial testing.\n",
    "\n",
    "For the detailed explanation of the data transformation and usage of the DeepAR model, please refer to the `model-creation-and-testing.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import DeepARPredictor, get_ssm_parameters\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.tuner import (\n",
    "    HyperparameterTuner,\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    ")\n",
    "from sagemaker.serializers import IdentitySerializer\n",
    "from sagemaker.deserializers import JSONDeserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation\n",
    "### Retrieve Parameters\n",
    "We collect here information from ssm parameters about:\n",
    "* the SageMake Feature Store storing our data\n",
    "* model target\n",
    "* model training hypertunning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ssm_parameters(ssm_client, param_path):\n",
    "    \"\"\"Retrieves the SSM parameters from the specified path\n",
    "\n",
    "    Args:\n",
    "        ssm_client (botocore.client): The SSM client\n",
    "        param_path (str): The path to the SSM parameters\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, str]: The SSM parameters\n",
    "    \"\"\"\n",
    "    parameters = {}\n",
    "    try:\n",
    "        response = ssm_client.get_parameters_by_path(\n",
    "            Path=param_path, Recursive=False, WithDecryption=False\n",
    "        )\n",
    "        for param in response[\"Parameters\"]:\n",
    "            parameters[param[\"Name\"].split(\"/\")[-1]] = param[\"Value\"]\n",
    "        while next_token := response.get(\"NextToken\"):\n",
    "            response = ssm_client.get_parameters_by_path(\n",
    "                Path=param_path,\n",
    "                Recursive=False,\n",
    "                WithDecryption=False,\n",
    "                NextToken=next_token,\n",
    "            )\n",
    "            for param in response[\"Parameters\"]:\n",
    "                parameters[param[\"Name\"].split(\"/\")[-1]] = param[\"Value\"]\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred reading the SSM stack parameters: {e}\")\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ssm_client = boto3.client(\"ssm\")\n",
    "# Read the Feature Group Name from SageMaker feature store\n",
    "stack_parameters = get_ssm_parameters(ssm_client, \"/rdi-mlops/stack-parameters\")\n",
    "# Read the SSM Parameters storing the parameters for the model training\n",
    "target_parameters = get_ssm_parameters(ssm_client, \"/rdi-mlops/sagemaker/model-build/target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seeds for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set S3 Buckets variables\n",
    "model_artifacts_bucket = f\"{stack_parameters['project-prefix']}-sagemaker-experiment-{stack_parameters['bucket-suffix']}\"\n",
    "# Set prefix used for all data stored within the bucket\n",
    "s3_model_prefix = \"deepar-model\"\n",
    "train_validation_data_folder_prefix = \"model-tuning\"\n",
    "s3_data_path = (\n",
    "    f\"s3://{model_artifacts_bucket}/data/{train_validation_data_folder_prefix}\"\n",
    ")\n",
    "s3_output_path = f\"s3://{model_artifacts_bucket}/{s3_model_prefix}/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set session variables\n",
    "sagemaker_session = sagemaker.Session(default_bucket=model_artifacts_bucket)\n",
    "region = sagemaker_session.boto_region_name\n",
    "account_id = sagemaker_session.account_id()\n",
    "role = sagemaker.get_execution_role()\n",
    "boto_session = boto3.Session(region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set boto3 S3 client\n",
    "s3 = boto3.resource(\"s3\")\n",
    "# Set feature store session\n",
    "sagemaker_client = boto_session.client(service_name=\"sagemaker\", region_name=region)\n",
    "featurestore_runtime = boto_session.client(\n",
    "    service_name=\"sagemaker-featurestore-runtime\", region_name=region\n",
    ")\n",
    "\n",
    "feature_store_session = Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data From FeatureStore\n",
    "The notebook uses Athena to load the data from the S3 bucket of the SageMaker Feature Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transactions_feature_group = FeatureGroup(\n",
    "    name=stack_parameters[\"sagemaker-feature-group-name\"],\n",
    "    sagemaker_session=feature_store_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transactions_feature_group.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the Data from FeatureStore using Athena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transactions_data_query = transactions_feature_group.athena_query()\n",
    "transactions_data_table = transactions_data_query.table_name\n",
    "\n",
    "query_string = f'SELECT * FROM \"{transactions_data_table}\"'\n",
    "\n",
    "# run Athena query. The output is loaded to a Pandas dataframe.\n",
    "# dataset = pd.DataFrame()\n",
    "transactions_data_query.run(\n",
    "    query_string=query_string,\n",
    "    output_location=\"s3://\" + model_artifacts_bucket + \"/query_results/\",\n",
    ")\n",
    "transactions_data_query.wait()\n",
    "df = transactions_data_query.as_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Dataset ETL:\n",
    "- sort the values by time\n",
    "- convert the time column from string to Pandas TImestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.sort_values(by=\"tx_minute\", axis=0, ascending=True, inplace=True)\n",
    "df[\"tx_minute\"] = pd.to_datetime(df[\"tx_minute\"])\n",
    "df.set_index(\"tx_minute\", drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Number of data points in the dataset: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Test and Validation Splits\n",
    "Prepare the train, test and validation datasets. Please refer to the `model-creation-and-testing.ipynb` notebook for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_dataset = df.index.min()\n",
    "end_dataset = df.index.max()\n",
    "freq = \"1min\"\n",
    "dataset_period = end_dataset - start_dataset\n",
    "num_validation_windows = int(target_parameters[\"num_validation_windows\"])\n",
    "target_col = target_parameters[\"target_col\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_nb_data_points = len(df)\n",
    "prediction_length = int(target_parameters[\"prediction_length\"])\n",
    "context_length = prediction_length\n",
    "test_length = prediction_length\n",
    "min_data_length = context_length + prediction_length * (num_validation_windows + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if total_nb_data_points < min_data_length:\n",
    "    prediction_length = int(total_nb_data_points * 0.05)\n",
    "    test_length = prediction_length\n",
    "    context_length = total_nb_data_points - prediction_length * (\n",
    "        num_validation_windows + 1\n",
    "    )\n",
    "validation_windows_length = num_validation_windows * prediction_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Formatting\n",
    "The data have to be formated to the DeepAR format as described in [this documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html#deepar-inputoutput)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = df[-test_length:]\n",
    "df_train_validation = df[:-test_length]\n",
    "df_train = df_train_validation[:-validation_windows_length]\n",
    "\n",
    "training_data = [\n",
    "    {\n",
    "        \"start\": str(start_dataset),\n",
    "        \"target\": list(df_train[target_col]),\n",
    "    }\n",
    "]\n",
    "validation_data = [\n",
    "    {\n",
    "        \"start\": str(start_dataset),\n",
    "        \"target\": list(\n",
    "            df_train_validation.iloc[\n",
    "                0 : -int((num_validation_windows - k) * prediction_length),\n",
    "                df_train_validation.columns.get_loc(target_col),\n",
    "            ]\n",
    "        ),\n",
    "    }\n",
    "    for k in range(1, num_validation_windows)\n",
    "]\n",
    "validation_data.append(\n",
    "    {\n",
    "        \"start\": str(start_dataset),\n",
    "        \"target\": list(df_train_validation[target_col]),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write the the train and test datasets JSON dictionaries file to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_dicts_to_file(path, data):\n",
    "    with open(path, \"wb\") as fp:\n",
    "        for d in data:\n",
    "            fp.write(json.dumps(d).encode(\"utf-8\"))\n",
    "            fp.write(\"\\n\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(train_validation_data_folder_prefix):\n",
    "    os.mkdir(train_validation_data_folder_prefix)\n",
    "write_dicts_to_file(f\"{train_validation_data_folder_prefix}/train.json\", training_data)\n",
    "write_dicts_to_file(\n",
    "    f\"{train_validation_data_folder_prefix}/validation.json\", validation_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def copy_to_s3(local_file, s3_path, override=False):\n",
    "    assert s3_path.startswith(\"s3://\")\n",
    "    split = s3_path.split(\"/\")\n",
    "    bucket = split[2]\n",
    "    path = \"/\".join(split[3:])\n",
    "    buk = s3.Bucket(bucket)\n",
    "\n",
    "    if len(list(buk.objects.filter(Prefix=path))) > 0:\n",
    "        if not override:\n",
    "            print(f\"File {s3_path} already exists.\\nSet override to upload anyway.\\n\")\n",
    "            return\n",
    "        else:\n",
    "            print(\"Overwriting existing file\")\n",
    "    with open(local_file, \"rb\") as data:\n",
    "        print(f\"Uploading file to {s3_path}\")\n",
    "        buk.put_object(Key=path, Body=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "copy_to_s3(\n",
    "    f\"{train_validation_data_folder_prefix}/train.json\",\n",
    "    s3_data_path + \"/train/train.json\",\n",
    "    override=True,\n",
    ")\n",
    "copy_to_s3(\n",
    "    f\"{train_validation_data_folder_prefix}/validation.json\",\n",
    "    s3_data_path + \"/validation/validation.json\",\n",
    "    override=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Model\n",
    "### Initialize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_name = sagemaker.image_uris.retrieve(\"forecasting-deepar\", region)\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=image_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.2xlarge\",\n",
    "    base_job_name=f\"{stack_parameters['project-prefix']}-deepar\",\n",
    "    use_spot_instances=True,\n",
    "    max_run=60 * 60 - 1,\n",
    "    max_wait=60 * 60,\n",
    "    output_path=s3_output_path,\n",
    ")\n",
    "\n",
    "data_channels = {\"train\": f\"{s3_data_path}/train/\", \"test\": f\"{s3_data_path}/validation/\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "}\n",
    "estimator.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"epochs\": IntegerParameter(50, 400),\n",
    "    \"mini_batch_size\": IntegerParameter(32, 128),\n",
    "    \"num_cells\": IntegerParameter(30, 100),\n",
    "    \"likelihood\": CategoricalParameter([\"gaussian\", \"student-T\"]),\n",
    "    \"learning_rate\": ContinuousParameter(1e-5, 1e-2),\n",
    "    \"dropout_rate\": ContinuousParameter(0.00, 0.2),\n",
    "    \"embedding_dimension\": IntegerParameter(5, 50),\n",
    "}\n",
    "\n",
    "# objective_metric_name=\"test:mean_wQuantileLoss\"\n",
    "objective_metric_name = \"test:mean_wQuantileLoss\"\n",
    "\n",
    "# Maximum number of models we will evaluate\n",
    "max_jobs = 80\n",
    "max_parallel_jobs = 5\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator=estimator,\n",
    "    objective_metric_name=objective_metric_name,\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    max_jobs=max_jobs,\n",
    "    strategy=\"Bayesian\",\n",
    "    random_seed=seed,\n",
    "    objective_type=\"Minimize\",\n",
    "    max_parallel_jobs=max_parallel_jobs,\n",
    "    early_stopping_type=\"Auto\",\n",
    ")\n",
    "\n",
    "# Start hyperparameter tuning job\n",
    "current_time = datetime.datetime.now().strftime(\"%d%m%Y%H%M\")\n",
    "tuning_job_name = f\"{stack_parameters['project-prefix']}-{current_time}\"\n",
    "tuner.fit(inputs=data_channels, job_name=tuning_job_name)\n",
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_training_job_name = tuner.best_training_job()\n",
    "print(f\" The name of the best training job is: {best_training_job_name}\")\n",
    "best_estimator = tuner.best_estimator()\n",
    "print(\n",
    "    f\" The best estimator hyperparamters are: {json.dumps(best_estimator.hyperparameters(), indent=2)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Endpoint and Predictor\n",
    "A utility class is created to query the endpoint and perform predictions. This class is mainly copied from the AWS [DeepAR demo notebook](https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/deepar_electricity/DeepAR-Electricity.ipynb)\n",
    "\n",
    "__Note: Remember to delete the endpoint after running this experiment. A cell at the very bottom of this notebook will do that: make sure you run it at the end.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint = tuner.deploy(\n",
    "    initial_instance_count=1,\n",
    "    endpoint_name=best_training_job_name,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    serializer=IdentitySerializer(content_type=\"application/json\"),\n",
    "    deserializer=JSONDeserializer(),\n",
    "    wait=True,\n",
    ")\n",
    "predictor = DeepARPredictor(\n",
    "    endpoint_name=endpoint.endpoint_name, sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Make Predictions and Plot Results\n",
    "We convert the train-test data to a Pandas Series and we use it to predict data points as defined in `prediction_length`.\n",
    "The predicted data are compared to the validation dataset to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the context data to time series\n",
    "ts = df.iloc[:-test_length, df.columns.get_loc(target_col)]\n",
    "# Convert the validation dataframe to a time series\n",
    "target_ts = df.iloc[-test_length:, df.columns.get_loc(target_col)]\n",
    "\n",
    "df_predictions = predictor.predict(ts=ts, quantiles=[0.10, 0.5, 0.90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot(\n",
    "    predictor,\n",
    "    ts,\n",
    "    target_ts,\n",
    "    freq=pd.Timedelta(1, \"min\"),\n",
    "    cat=None,\n",
    "    show_samples=False,\n",
    "    confidence=80,\n",
    "):\n",
    "    forecast_start_date = target_ts.index[0]\n",
    "    print(\n",
    "        \"calling served model to generate predictions starting from {}\".format(\n",
    "            str(forecast_start_date)\n",
    "        )\n",
    "    )\n",
    "    assert confidence > 50 and confidence < 100\n",
    "    low_quantile = 0.5 - confidence * 0.005\n",
    "    up_quantile = confidence * 0.005 + 0.5\n",
    "\n",
    "    # we first construct the argument to call our model\n",
    "    args = {\n",
    "        \"ts\": ts,\n",
    "        \"return_samples\": show_samples,\n",
    "        \"quantiles\": [low_quantile, 0.5, up_quantile],\n",
    "        \"num_samples\": 100,\n",
    "    }\n",
    "\n",
    "    plt.figure(figsize=(20, 3))\n",
    "    ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "    if cat is not None:\n",
    "        args[\"cat\"] = cat\n",
    "        ax.text(0.9, 0.9, \"cat = {}\".format(cat), transform=ax.transAxes)\n",
    "\n",
    "    # call the end point to get the prediction\n",
    "    prediction = predictor.predict(**args)\n",
    "\n",
    "    # plot the samples\n",
    "    if show_samples:\n",
    "        for key in prediction.keys():\n",
    "            if \"sample\" in key:\n",
    "                prediction[key].plot(\n",
    "                    color=\"lightskyblue\", alpha=0.2, label=\"_nolegend_\"\n",
    "                )\n",
    "\n",
    "    # plot the target\n",
    "    target_ts.plot(color=\"black\", label=\"target\")\n",
    "\n",
    "    # plot the confidence interval and the median predicted\n",
    "    ax.fill_between(\n",
    "        prediction[str(low_quantile)].index,\n",
    "        prediction[str(low_quantile)].values,\n",
    "        prediction[str(up_quantile)].values,\n",
    "        color=\"b\",\n",
    "        alpha=0.3,\n",
    "        label=\"{}% confidence interval\".format(confidence),\n",
    "    )\n",
    "    prediction[\"0.5\"].plot(color=\"b\", label=\"P50\")\n",
    "    ax.legend(loc=2)\n",
    "\n",
    "    # fix the scale as the samples may change it\n",
    "    ax.set_ylim(target_ts.min() * 0.5, target_ts.max() * 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot(\n",
    "    predictor,\n",
    "    ts=ts,\n",
    "    target_ts=target_ts,\n",
    "    show_samples=False,\n",
    "    confidence=60,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "Delete the model & endpoint used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
